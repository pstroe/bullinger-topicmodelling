{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70346ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phillip/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "import lxml.etree as etree\n",
    "import gensim\n",
    "from cltk import NLP\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31e43d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cltk 1.1.6 (/home/phillip/.local/lib/python3.10/site-packages)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cltk\n",
    "cltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d7886af",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbbw_xmls = glob.glob('/home/phillip/Documents/uzh/phd/bullinger/bullinger-korpus/data/editions/hbbw/*/*.xml')\n",
    "vbs_xmls = glob.glob('/home/phillip/Documents/uzh/phd/bullinger/bullinger-korpus/data/editions/vbs/*/*.xml')\n",
    "transcribed_xmls = glob.glob('/home/phillip/Documents/uzh/phd/bullinger/bullinger-korpus/data/non_edited/transcribed/*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "919af077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8640"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_xmls = hbbw_xmls + vbs_xmls + transcribed_xmls\n",
    "len(all_xmls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6697ceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äéê§Ä CLTK version '1.1.6'.\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.\n"
     ]
    }
   ],
   "source": [
    "la_nlp = NLP('lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d1b08f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cltk.alphabet.processes.LatinNormalizeProcess,\n",
       " cltk.dependency.processes.LatinStanzaProcess,\n",
       " cltk.embeddings.processes.LatinEmbeddingsProcess]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_nlp.pipeline.processes.pop(-1)\n",
    "la_nlp.pipeline.processes.pop(-1)\n",
    "la_nlp.pipeline.processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61af5cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minoritam\n",
      "ecclesia\n",
      "numerus\n",
      "viaticum\n",
      "opus\n",
      "potestate\n",
      "Odium\n",
      "primatum\n",
      "domino\n",
      "Oris\n",
      "linguƒô\n",
      "parhisia\n",
      "animorum\n",
      "asperitate\n",
      "consolatio\n",
      "testimonium\n",
      "dominus\n",
      "tabellio\n",
      "casu\n",
      "literas\n",
      "Arcana\n",
      "domino\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "normalize() argument 2 must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mla\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mla_nlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mwords:\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m w\u001b[38;5;241m.\u001b[39mupos \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m w\u001b[38;5;241m.\u001b[39mupos \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROPN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cltk/nlp.py:169\u001b[0m, in \u001b[0;36mNLP.__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cltk/nlp.py:141\u001b[0m, in \u001b[0;36mNLP.analyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m process \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mprocesses:\n\u001b[1;32m    140\u001b[0m     a_process \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_process_object(process)\n\u001b[0;32m--> 141\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43ma_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cltk/alphabet/processes.py:29\u001b[0m, in \u001b[0;36mNormalizeProcess.run\u001b[0;34m(self, input_doc)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_doc: Doc) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124;03m\"\"\"This ideally returns an algorithm that takes and returns a string.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     normalized_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_doc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     input_doc\u001b[38;5;241m.\u001b[39mnormalized_text \u001b[38;5;241m=\u001b[39m normalized_text\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m input_doc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cltk/alphabet/lat.py:476\u001b[0m, in \u001b[0;36mnormalize_lat\u001b[0;34m(text, drop_accents, drop_macrons, jv_replacement, ligature_replacement)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_lat\u001b[39m(\n\u001b[1;32m    451\u001b[0m     text: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    452\u001b[0m     drop_accents: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m     ligature_replacement: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    456\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;124;03m\"\"\"The function for all default Latin normalization.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    >>> text = \"can≈ç ƒ™uliƒ´ suspensaÃÅm quaÃÜm aegeÃÅrrume iÃÜndignu iÃÇs oÃÅccidentem fruÃÅges Julius Caesar. In vino veritas. m√¶d pr≈ìil\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    474\u001b[0m \n\u001b[1;32m    475\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m     text_cltk_normalized: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcltk_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# text_cltk_normalized = split_trailing_punct(text=text_cltk_normalized)\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;66;03m# text_cltk_normalized = split_leading_punct(text=text_cltk_normalized)\u001b[39;00m\n\u001b[1;32m    479\u001b[0m     text_cltk_normalized \u001b[38;5;241m=\u001b[39m remove_odd_punct(text\u001b[38;5;241m=\u001b[39mtext_cltk_normalized)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/cltk/alphabet/text_normalization.py:9\u001b[0m, in \u001b[0;36mcltk_normalize\u001b[0;34m(text, compatibility)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcltk_normalize\u001b[39m(text, compatibility\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compatibility:\n\u001b[0;32m----> 9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNFKC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m normalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNFC\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "\u001b[0;31mTypeError\u001b[0m: normalize() argument 2 must be str, not None"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for xml in all_xmls:\n",
    "    text = []\n",
    "    xml_open = etree.parse(open(xml, 'r'))\n",
    "    xml_name = xml.split('/')[-1].replace('.xml', '') \n",
    "    root = xml_open.getroot()\n",
    "    sentences = root.findall('.//s')\n",
    "    for s in sentences:\n",
    "        if s.get('lang') == 'la':\n",
    "            doc = la_nlp(s.text)\n",
    "            for w in doc.words:\n",
    "                if w.upos == 'NOUN' or w.upos == 'PROPN':\n",
    "                    print(w.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6487d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
